local stringx = require('pl.stringx')
local cmd = torch.CmdLine()
cmd:option("-batch_size",64,"batch size")
cmd:option("-dimension",1024,"vector dimensionality")
cmd:option("-dropout",0.2,"dropout rate")
cmd:option("-train_file","","")
cmd:option("-dev_file","","")
cmd:option("-test_file","","")
cmd:option("-init_weight",0.1,"")
cmd:option("-alpha",1,"")
cmd:option("-start_halve",6,"")
cmd:option("-max_length",100,"");
cmd:option("-vocab_source",25010,"")
cmd:option("-vocab_target",25010,"")
cmd:option("-thres",5,"gradient clipping thres")
cmd:option("-max_iter",8,"max number of iteration")
cmd:option("-source_max_length",50,"")
cmd:option("-target_max_length",50,"")
cmd:option("-layers",2,"")
cmd:option("-saveFolder","save","")
cmd:option("-save_prefix","","")
cmd:option("-save_params_file","","")
cmd:option("-output_file","","")
cmd:option("-reverse",false,"")
cmd:option("-reverse_target",false,"")
cmd:option("-gpu_index",1,"the index of GPU to use")
cmd:option("-saveModel",true,"")
cmd:option("-dictPath","../data/movie_25000","")
cmd:option("-SpeakerNum",10000,"number of distinct speakers")
cmd:option("-AddresseeNum",10000,"number of distinct addressees")
cmd:option("-speakerSetting","speaker","taking values of speaker or speaker_addressee; speaker: only model the user who speaks; speaker_addressee: modeling both the speaker and the addressee");
local params= cmd:parse(arg)
params.save_prefix=params.saveFolder.."/model"
params.save_params_file=params.saveFolder.."/params"
params.output_file=params.saveFolder.."/log"
paths.mkdir(params.saveFolder)
print(params)
return params;
